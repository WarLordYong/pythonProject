{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddleNLP实战：应用NeZha模型做微博情感6分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一.项目介绍\n",
    "\n",
    "## 1.1 项目背景\n",
    "情感分析技术一直是自然语言处理领域研究的重点内容之一。2020年，新冠肺炎疫情成为了全国人民关注的焦点，众多用户针对此次疫情在新浪微博等社交媒体平台上发表自己的看法，蕴含了非常丰富的情感信息。基于自然语言处理技术自动识别社交媒体文本中的情绪信息，可以帮助政府了解网民对各个事件的态度，及时发现人民的情绪波动，从而更有针对性地制定政策方针，具有重要的社会价值。尽管之前的社交媒体情感分析技术已经取得了不错的进展，但是如何将之前的研究成果快速高效地应用到疫情相关的数据当中，仍然是一个值得研究的问题。\n",
    "\n",
    "## 1.2 项目简介\n",
    "本项目主要基于PaddleNLP通过预训练模型NeZha在SMP2020微博情绪分类数据集上的微调完成6分类微情感分析模型的训练与优化，将微博文本按照其蕴含的情绪分为以下六个类别之一：neutral（无情绪）、happy（积极）、angry（愤怒）、sad（悲伤）、fear（恐惧）、surprise（惊奇）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/af7261ab63b54858952b55ec6064c92c078908b444a24844b15754ddd97a0fca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二.SMP2020微博情绪6分类数据集\n",
    "\n",
    "数据来源：SMP2020微博情绪分类技术评测 [http://39.97.118.137/](http://39.97.118.137/)\n",
    "\n",
    "本次使用数据集为SMP2020微博情绪分类技术评测数据集（SMP2020-EWECT）\n",
    "\n",
    "该技术评测使用的标注数据集由哈尔滨工业大学社会计算与信息检索研究中心提供，原始数据源于新浪微博，由微热点大数据研究院提供，数据集分为两部分。\n",
    "\n",
    "第一部分为通用微博数据集，该数据集内的微博内容是随机获取到微博内容，不针对特定的话题，覆盖的范围较广。\n",
    "\n",
    "第二部分为疫情微博数据集，该数据集内的微博内容是在疫情期间使用相关关键字筛选获得的疫情微博，其内容与新冠疫情相关。\n",
    "\n",
    "每条微博被标注为以下六个类别之一：neutral（无情绪）、happy（积极）、angry（愤怒）、sad（悲伤）、fear（恐惧）、surprise（惊奇）。\n",
    "\n",
    "通用微博训练数据集包括27,768条微博，验证集包含2,000条微博，测试数据集包含5,000条微博。\n",
    "\n",
    "疫情微博训练数据集包括8,606条微博，验证集包含2,000条微博，测试数据集包含3,000条微博。\n",
    "\n",
    "经处理后的该数据集已上传AI Studio，[https://aistudio.baidu.com/aistudio/datasetdetail/104703/0](https://aistudio.baidu.com/aistudio/datasetdetail/104703/0)\n",
    "数据集以csv格式存储，包含三列：数据编号，文本，情绪标签。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/8affa7dad192424880fbdfb3ce80c24a2b2b8f259bbe48c8a9700d5b4c3a9c0b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 解压并处理数据集\n",
    "训练、验证和测试集的划分上主要按照其官网默认的划分形式，感兴趣的也可以对其进行自定义划分！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:13:58.168004Z",
     "iopub.status.busy": "2023-04-12T02:13:58.167715Z",
     "iopub.status.idle": "2023-04-12T02:13:58.764258Z",
     "shell.execute_reply": "2023-04-12T02:13:58.763236Z",
     "shell.execute_reply.started": "2023-04-12T02:13:58.167933Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data/data104703\r\n",
      "Archive:  data.zip\r\n",
      "  inflating: usual_eval_labeled.csv  \r\n",
      "  inflating: usual_test_labeled.csv  \r\n",
      "  inflating: usual_train.csv         \r\n",
      "  inflating: virus_eval_labeled.csv  \r\n",
      "  inflating: virus_test_labeled.csv  \r\n",
      "  inflating: virus_train.csv         \r\n"
     ]
    }
   ],
   "source": [
    "# 解压数据集\n",
    "%cd /home/aistudio/data/data104703/\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:13:58.765648Z",
     "iopub.status.busy": "2023-04-12T02:13:58.765405Z",
     "iopub.status.idle": "2023-04-12T02:13:59.316835Z",
     "shell.execute_reply": "2023-04-12T02:13:59.315745Z",
     "shell.execute_reply.started": "2023-04-12T02:13:58.765624Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 通过pandas读取并处理数据\n",
    "import pandas as pd\n",
    "\n",
    "train1 = pd.read_csv('./virus_train.csv')  # 疫情微博训练数据集\n",
    "train2 = pd.read_csv('./usual_train.csv')  # 通用微博训练数据集\n",
    "train = pd.concat([train1,train2])  # 拼接训练集\n",
    "\n",
    "eval1 = pd.read_csv('./virus_eval_labeled.csv')  # 疫情微博验证数据集\n",
    "eval2 = pd.read_csv('./usual_eval_labeled.csv')  # 通用微博验证数据集\n",
    "eval = pd.concat([eval1,eval2])  # 拼接验证集\n",
    "\n",
    "test1 = pd.read_csv('./virus_test_labeled.csv')  # 疫情微博测试数据集\n",
    "test2 = pd.read_csv('./usual_test_labeled.csv')  # 通用微博测试数据集\n",
    "test = pd.concat([test1,test2])  # 拼接测试集\n",
    "\n",
    "total = pd.concat([train,eval,test])  # 构造总数据集便于统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:13:59.318735Z",
     "iopub.status.busy": "2023-04-12T02:13:59.318296Z",
     "iopub.status.idle": "2023-04-12T02:13:59.436036Z",
     "shell.execute_reply": "2023-04-12T02:13:59.435170Z",
     "shell.execute_reply.started": "2023-04-12T02:13:59.318709Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将数据处理为text_a,label的格式便于进行统一处理\n",
    "train['label'] = train['情绪标签']\n",
    "eval['label'] = eval['情绪标签']\n",
    "test['label'] = test['情绪标签']\n",
    "total['label'] = total['情绪标签']\n",
    "\n",
    "train['text_a'] = train['文本']\n",
    "eval['text_a'] = eval['文本']\n",
    "test['text_a'] = test['文本']\n",
    "total['text_a'] = total['文本']\n",
    "\n",
    "train = train[['text_a', 'label']]\n",
    "eval = eval[['text_a', 'label']]\n",
    "test = test[['text_a', 'label']]\n",
    "total = total[['text_a', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 数据分析EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:13:59.438914Z",
     "iopub.status.busy": "2023-04-12T02:13:59.438328Z",
     "iopub.status.idle": "2023-04-12T02:14:00.352309Z",
     "shell.execute_reply": "2023-04-12T02:14:00.351486Z",
     "shell.execute_reply.started": "2023-04-12T02:13:59.438887Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>天使</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>致敬[心][心]小凡也要做好防护措施哦//@Mr_凡先生:致敬[心]大家出门记得戴口罩</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[中国赞][中国赞][中国赞]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>悲壮</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>！！！一定会好起来</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_a  label\n",
       "0                                           天使  happy\n",
       "1  致敬[心][心]小凡也要做好防护措施哦//@Mr_凡先生:致敬[心]大家出门记得戴口罩  happy\n",
       "2                              [中国赞][中国赞][中国赞]  happy\n",
       "3                                           悲壮    sad\n",
       "4                                    ！！！一定会好起来  happy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据前5条\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:00.356407Z",
     "iopub.status.busy": "2023-04-12T02:14:00.355929Z",
     "iopub.status.idle": "2023-04-12T02:14:01.623106Z",
     "shell.execute_reply": "2023-04-12T02:14:01.622237Z",
     "shell.execute_reply.started": "2023-04-12T02:14:00.356381Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\r\n",
      "Int64Index: 48374 entries, 0 to 4999\r\n",
      "Data columns (total 2 columns):\r\n",
      " #   Column  Non-Null Count  Dtype \r\n",
      "---  ------  --------------  ----- \r\n",
      " 0   text_a  48372 non-null  object\r\n",
      " 1   label   48374 non-null  object\r\n",
      "dtypes: object(2)\r\n",
      "memory usage: 1.1+ MB\r\n"
     ]
    }
   ],
   "source": [
    "# 查看总数据文件信息,可以看出共计有48374条数据\n",
    "total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:01.624901Z",
     "iopub.status.busy": "2023-04-12T02:14:01.624231Z",
     "iopub.status.idle": "2023-04-12T02:14:02.285413Z",
     "shell.execute_reply": "2023-04-12T02:14:02.284538Z",
     "shell.execute_reply.started": "2023-04-12T02:14:01.624874Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\r\n",
      "Int64Index: 36374 entries, 0 to 27767\r\n",
      "Data columns (total 2 columns):\r\n",
      " #   Column  Non-Null Count  Dtype \r\n",
      "---  ------  --------------  ----- \r\n",
      " 0   text_a  36372 non-null  object\r\n",
      " 1   label   36374 non-null  object\r\n",
      "dtypes: object(2)\r\n",
      "memory usage: 852.5+ KB\r\n"
     ]
    }
   ],
   "source": [
    "# 查看训练数据文件信息\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:02.287171Z",
     "iopub.status.busy": "2023-04-12T02:14:02.286596Z",
     "iopub.status.idle": "2023-04-12T02:14:03.250351Z",
     "shell.execute_reply": "2023-04-12T02:14:03.249441Z",
     "shell.execute_reply.started": "2023-04-12T02:14:02.287143Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 通过上面的分析可以看出text_a文本列是存在缺失值的，直接清除缺失值所在行\n",
    "train = train.dropna(subset=['text_a'])\n",
    "total = total.dropna(subset=['text_a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:03.252072Z",
     "iopub.status.busy": "2023-04-12T02:14:03.251507Z",
     "iopub.status.idle": "2023-04-12T02:14:04.430141Z",
     "shell.execute_reply": "2023-04-12T02:14:04.429473Z",
     "shell.execute_reply.started": "2023-04-12T02:14:03.252045Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48372.000000\n",
       "mean        46.011081\n",
       "std         47.914503\n",
       "min          2.000000\n",
       "25%         21.000000\n",
       "50%         33.000000\n",
       "75%         56.000000\n",
       "max       3172.000000\n",
       "Name: text_a, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计文本长度，便于确定文本最大截断长度\n",
    "total['text_a'].map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据文本长度分析可以看出文本总体上属于短文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:04.431863Z",
     "iopub.status.busy": "2023-04-12T02:14:04.431166Z",
     "iopub.status.idle": "2023-04-12T02:14:05.707038Z",
     "shell.execute_reply": "2023-04-12T02:14:05.706374Z",
     "shell.execute_reply.started": "2023-04-12T02:14:04.431836Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       13673\n",
       "angry       12536\n",
       "neutral      9615\n",
       "sad          7269\n",
       "surprise     2942\n",
       "fear         2337\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计数据集中类别标签的分布情况\n",
    "total['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:05.708632Z",
     "iopub.status.busy": "2023-04-12T02:14:05.707987Z",
     "iopub.status.idle": "2023-04-12T02:14:07.759895Z",
     "shell.execute_reply": "2023-04-12T02:14:07.759129Z",
     "shell.execute_reply.started": "2023-04-12T02:14:05.708605Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化类别标签分布情况\n",
    "%matplotlib inline\n",
    "total['label'].value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:07.761496Z",
     "iopub.status.busy": "2023-04-12T02:14:07.760958Z",
     "iopub.status.idle": "2023-04-12T02:14:08.209212Z",
     "shell.execute_reply": "2023-04-12T02:14:08.208417Z",
     "shell.execute_reply.started": "2023-04-12T02:14:07.761468Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 对处理后的数据进行存储，格式统一为text_a,label\n",
    "train.to_csv('train.csv', sep='\\t', index=False)\n",
    "eval.to_csv('valid.csv', sep='\\t', index=False)\n",
    "test.to_csv('test.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三.基于PaddleNLP构建微情感分析模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/3bb5aa3806b745c49a5958fe1590ad11c8204527f56540e38a25dc61364e230e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 前置环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:08.213429Z",
     "iopub.status.busy": "2023-04-12T02:14:08.212743Z",
     "iopub.status.idle": "2023-04-12T02:14:10.181524Z",
     "shell.execute_reply": "2023-04-12T02:14:10.179770Z",
     "shell.execute_reply.started": "2023-04-12T02:14:08.213401Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入所需的第三方库\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "from functools import partial\n",
    "import random\n",
    "import time\n",
    "import inspect\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import IterableDataset\n",
    "from paddle.utils.download import get_path_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:10.184366Z",
     "iopub.status.busy": "2023-04-12T02:14:10.183648Z",
     "iopub.status.idle": "2023-04-12T02:14:18.558537Z",
     "shell.execute_reply": "2023-04-12T02:14:18.557120Z",
     "shell.execute_reply.started": "2023-04-12T02:14:10.184327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.4.2)\r\n",
      "Collecting paddlenlp\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e4/67/f97788181e3a49afcdf8ffa162a335c21d18a55387bae85be24b01383165/paddlenlp-2.5.2-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: Flask-Babel<3.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: uvicorn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.21.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\r\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\r\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.4.0)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.7.0)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.1)\r\n",
      "Collecting huggingface-hub>=0.11.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/90/5ad98abead047169f4f86bc67e99020c841d71c9c6bd202e04af71e70e53/huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m416.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting typer\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0d/44/56c3f48d2bb83d76f5c970aef8e2c3ebd6a832f09e3621c5395371fe6999/typer-0.7.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: rich in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (12.6.0)\r\n",
      "Requirement already satisfied: fastapi in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.95.0)\r\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.3.3)\r\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.96)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.19.5)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2.24.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.1.5)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (10.0.0)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (5.1.2)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2022.11.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (4.2.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.1.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.3)\r\n",
      "Requirement already satisfied: Flask in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel<3.0.0->paddlenlp) (1.1.1)\r\n",
      "Requirement already satisfied: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel<3.0.0->paddlenlp) (3.0.0)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel<3.0.0->paddlenlp) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel<3.0.0->paddlenlp) (2019.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.0.12)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.3.0)\r\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from fastapi->paddlenlp) (0.26.1)\r\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from fastapi->paddlenlp) (1.10.6)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (2.13.0)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (0.9.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from typer->paddlenlp) (8.0.4)\r\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from uvicorn->paddlenlp) (0.14.0)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.16.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\r\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.20.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\r\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (8.2.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (0.16.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (22.1.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.1.1)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (0.13.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel<3.0.0->paddlenlp) (2.0.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.25.11)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from starlette<0.27.0,>=0.26.1->fastapi->paddlenlp) (3.6.1)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\r\n",
      "Installing collected packages: huggingface-hub, typer, paddlenlp\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.11.0\r\n",
      "    Uninstalling huggingface-hub-0.11.0:\r\n",
      "      Successfully uninstalled huggingface-hub-0.11.0\r\n",
      "  Attempting uninstall: paddlenlp\r\n",
      "    Found existing installation: paddlenlp 2.4.2\r\n",
      "    Uninstalling paddlenlp-2.4.2:\r\n",
      "      Successfully uninstalled paddlenlp-2.4.2\r\n",
      "Successfully installed huggingface-hub-0.13.4 paddlenlp-2.5.2 typer-0.7.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# 下载最新版本的paddlenlp\n",
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:18.561376Z",
     "iopub.status.busy": "2023-04-12T02:14:18.560426Z",
     "iopub.status.idle": "2023-04-12T02:14:19.894738Z",
     "shell.execute_reply": "2023-04-12T02:14:19.893749Z",
     "shell.execute_reply.started": "2023-04-12T02:14:18.561337Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入paddlenlp相关的包\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import JiebaTokenizer, Pad, Stack, Tuple, Vocab\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.dataset.common import md5file\n",
    "from paddlenlp.datasets import DatasetBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 定义要进行微调的预训练模型\n",
    "此次使用华为的NeZha模型，该模型目前在中文领域上效果较优。 \n",
    "\n",
    "同时预训练模型一般“大力出奇迹”，选用大的预训练模型往往可以取得比base模型更优的效果\n",
    "\n",
    "PaddleNLP支持的更多预训练模型：[https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/0b9773f6d7454f459f5e1359b3b064223e4a83add47a4402a5c80a8f6b1c8fbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:19.897071Z",
     "iopub.status.busy": "2023-04-12T02:14:19.895984Z",
     "iopub.status.idle": "2023-04-12T02:14:48.326968Z",
     "shell.execute_reply": "2023-04-12T02:14:48.326214Z",
     "shell.execute_reply.started": "2023-04-12T02:14:19.897039Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-12 10:14:19,899] [    INFO] - Model config NeZhaConfig {\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"classifier_dropout\": 0.1,\r\n",
      "  \"embedding_size\": 128,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\",\r\n",
      "    \"3\": \"LABEL_3\",\r\n",
      "    \"4\": \"LABEL_4\",\r\n",
      "    \"5\": \"LABEL_5\"\r\n",
      "  },\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 4096,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2,\r\n",
      "    \"LABEL_3\": 3,\r\n",
      "    \"LABEL_4\": 4,\r\n",
      "    \"LABEL_5\": 5\r\n",
      "  },\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 512,\r\n",
      "  \"max_relative_position\": 64,\r\n",
      "  \"model_type\": \"nezha\",\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 24,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"type_vocab_size\": 2,\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_relative_position\": true,\r\n",
      "  \"vocab_size\": 21128\r\n",
      "}\r\n",
      "\r\n",
      "[2023-04-12 10:14:19,903] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/models/nezha-large-wwm-chinese/config.json\r\n",
      "[2023-04-12 10:14:19,905] [    INFO] - Downloading nezha-large-wwm-chinese.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/nezha/nezha-large-wwm-chinese.pdparams\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dc4d5515a9451483ccecfef4d8d4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.30G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:14:45.791545   183 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0412 10:14:45.795081   183 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-04-12 10:14:48,319] [ WARNING] - Some weights of the model checkpoint at nezha-large-wwm-chinese were not used when initializing NeZhaForSequenceClassification: ['cls.predictions.layer_norm.bias', 'cls.seq_relationship.bias', 'cls.predictions.dense.bias', 'cls.predictions.decoder_bias', 'cls.seq_relationship.weight', 'cls.predictions.layer_norm.weight', 'cls.predictions.decoder_weight', 'cls.predictions.dense.weight']\r\n",
      "- This IS expected if you are initializing NeZhaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing NeZhaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "[2023-04-12 10:14:48,321] [ WARNING] - Some weights of NeZhaForSequenceClassification were not initialized from the model checkpoint at nezha-large-wwm-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n"
     ]
    }
   ],
   "source": [
    "# 只需指定想要使用的模型名称和文本分类的类别数即可完成Fine-tune网络定义，通过在预训练模型后拼接上一个全连接网络（Full Connected）进行分类\n",
    "# 由于本任务中的情感分类是6分类问题，设定num_classes为6\n",
    "# 此次需要注意，要修改使用Nezha以外其他模型的话，需要修改下NeZhaForSequenceClassification和NeZhaTokenizer，具体修改可以查看paddlenlp的api文档\n",
    "model = ppnlp.transformers.NeZhaForSequenceClassification.from_pretrained('nezha-large-wwm-chinese', num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:48.328939Z",
     "iopub.status.busy": "2023-04-12T02:14:48.328464Z",
     "iopub.status.idle": "2023-04-12T02:14:48.515369Z",
     "shell.execute_reply": "2023-04-12T02:14:48.514563Z",
     "shell.execute_reply.started": "2023-04-12T02:14:48.328905Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-12 10:14:48,334] [    INFO] - Downloading http://bj.bcebos.com/paddlenlp/models/transformers/nezha/nezha-chinese-vocab.txt and saved to /home/aistudio/.paddlenlp/models/nezha-large-wwm-chinese\r\n",
      "[2023-04-12 10:14:48,377] [    INFO] - Downloading nezha-chinese-vocab.txt from http://bj.bcebos.com/paddlenlp/models/transformers/nezha/nezha-chinese-vocab.txt\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f420dfb9174d9a9519bab1d458a228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-12 10:14:48,508] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/nezha-large-wwm-chinese/tokenizer_config.json\r\n",
      "[2023-04-12 10:14:48,510] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/nezha-large-wwm-chinese/special_tokens_map.json\r\n"
     ]
    }
   ],
   "source": [
    "#调用ppnlp.transformers.BertTokenizer进行数据处理，tokenizer可以把原始输入文本转化成模型model可接受的输入数据格式。\n",
    "tokenizer =  ppnlp.transformers.NeZhaTokenizer.from_pretrained('nezha-large-wwm-chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 数据读取和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:48.517142Z",
     "iopub.status.busy": "2023-04-12T02:14:48.516588Z",
     "iopub.status.idle": "2023-04-12T02:14:48.844885Z",
     "shell.execute_reply": "2023-04-12T02:14:48.843934Z",
     "shell.execute_reply.started": "2023-04-12T02:14:48.517116Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'sad', 'neutral', 'fear', 'angry', 'surprise']\r\n"
     ]
    }
   ],
   "source": [
    "# 定义要进行分类的类别\n",
    "label_list=list(train.label.unique())\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:48.846733Z",
     "iopub.status.busy": "2023-04-12T02:14:48.846029Z",
     "iopub.status.idle": "2023-04-12T02:14:49.360748Z",
     "shell.execute_reply": "2023-04-12T02:14:49.359890Z",
     "shell.execute_reply.started": "2023-04-12T02:14:48.846707Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据集对应文件及其文件存储格式\n",
    "class EmotionData(DatasetBuilder):\n",
    "    SPLITS = {\n",
    "        'train': 'train.csv',  # 训练集\n",
    "        'dev': 'valid.csv',    # 验证集\n",
    "        'test': 'test.csv',    # 测试集\n",
    "    }\n",
    "\n",
    "    def _get_data(self, mode, **kwargs):\n",
    "        filename = self.SPLITS[mode]\n",
    "        return filename\n",
    "\n",
    "    def _read(self, filename):\n",
    "        \"\"\"读取数据\"\"\"\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            head = None\n",
    "            for line in f:\n",
    "                data = line.strip().split(\"\\t\")    # 以'\\t'分隔各列\n",
    "                if not head:\n",
    "                    head = data\n",
    "                else:\n",
    "                    text_a, label = data\n",
    "                    yield {\"text_a\": text_a, \"label\": label}  # 数据的格式：text_a,label\n",
    "\n",
    "    def get_labels(self):\n",
    "        return label_list   # 类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:49.362600Z",
     "iopub.status.busy": "2023-04-12T02:14:49.361904Z",
     "iopub.status.idle": "2023-04-12T02:14:50.063092Z",
     "shell.execute_reply": "2023-04-12T02:14:50.062256Z",
     "shell.execute_reply.started": "2023-04-12T02:14:49.362572Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据集加载函数\n",
    "def load_dataset(name=None,\n",
    "                 data_files=None,\n",
    "                 splits=None,\n",
    "                 lazy=None,\n",
    "                 **kwargs):\n",
    "   \n",
    "    reader_cls = EmotionData\n",
    "    print(reader_cls)\n",
    "    if not name:\n",
    "        reader_instance = reader_cls(lazy=lazy, **kwargs)\n",
    "    else:\n",
    "        reader_instance = reader_cls(lazy=lazy, name=name, **kwargs)\n",
    "\n",
    "    datasets = reader_instance.read_datasets(data_files=data_files, splits=splits)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:50.064887Z",
     "iopub.status.busy": "2023-04-12T02:14:50.064222Z",
     "iopub.status.idle": "2023-04-12T02:14:50.730399Z",
     "shell.execute_reply": "2023-04-12T02:14:50.729567Z",
     "shell.execute_reply.started": "2023-04-12T02:14:50.064861Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.EmotionData'>\r\n"
     ]
    }
   ],
   "source": [
    "# 加载训练、验证集和测试集\n",
    "train_ds, dev_ds, test_ds = load_dataset(splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:50.732042Z",
     "iopub.status.busy": "2023-04-12T02:14:50.731389Z",
     "iopub.status.idle": "2023-04-12T02:14:51.018527Z",
     "shell.execute_reply": "2023-04-12T02:14:51.017679Z",
     "shell.execute_reply.started": "2023-04-12T02:14:50.732012Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据加载和处理函数\n",
    "def convert_example(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "    qtconcat = example[\"text_a\"]\n",
    "    encoded_inputs = tokenizer(text=qtconcat, max_seq_len=max_seq_length)\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n",
    "\n",
    "# 数据加载函数dataloader\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:51.020355Z",
     "iopub.status.busy": "2023-04-12T02:14:51.019561Z",
     "iopub.status.idle": "2023-04-12T02:14:51.430879Z",
     "shell.execute_reply": "2023-04-12T02:14:51.430064Z",
     "shell.execute_reply.started": "2023-04-12T02:14:51.020327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 批处理大小，显存如若不足的话可以适当改小该值  \n",
    "batch_size = 32\n",
    "# 文本序列最大截断长度，需要根据文本具体长度进行确定，不超过512\n",
    "max_seq_length = 128\n",
    "\n",
    "# 将数据处理成模型可读入的数据格式\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length)\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\n",
    "    Stack()  # labels\n",
    "): [data for data in fn(samples)]\n",
    "\n",
    "# 训练集迭代器\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)\n",
    "\n",
    "# 验证集迭代器\n",
    "dev_data_loader = create_dataloader(\n",
    "    dev_ds,\n",
    "    mode='dev',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)\n",
    "\n",
    "# 测试集迭代器\n",
    "test_data_loader = create_dataloader(\n",
    "    test_ds, \n",
    "    mode='test', \n",
    "    batch_size=batch_size, \n",
    "    batchify_fn=batchify_fn, \n",
    "    trans_fn=trans_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 设置Fine-Tune优化策略，接入评价指标\n",
    "适用于ERNIE/BERT这类Transformer模型的学习率为warmup的动态学习率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/56fbfd6649404638baecb1e6ebbd405e20f19ecb6d994b99b1562cdc7265d06a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:51.432253Z",
     "iopub.status.busy": "2023-04-12T02:14:51.432004Z",
     "iopub.status.idle": "2023-04-12T02:14:52.077813Z",
     "shell.execute_reply": "2023-04-12T02:14:52.077065Z",
     "shell.execute_reply.started": "2023-04-12T02:14:51.432231Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义超参，loss，优化器等\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "# 定义训练过程中的最大学习率\n",
    "learning_rate = 2e-5\n",
    "# 训练轮次\n",
    "epochs = 4\n",
    "# 学习率预热比例\n",
    "warmup_proportion = 0.1\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\n",
    "weight_decay = 0.01\n",
    "\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "\n",
    "# AdamW优化器\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ])\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "metric = paddle.metric.Accuracy()  # accuracy评价指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 模型训练与评估\n",
    "ps：模型训练时，可以通过在终端输入**nvdia-smi**命令或者通过点击底部‘性能监控’选项查看显存的占用情况，适当调整好batchsize。\n",
    "\n",
    "若显存仍然不足的话，可以考虑下使用些轻量级的预训练模型如ERNIE-tiny等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:52.079388Z",
     "iopub.status.busy": "2023-04-12T02:14:52.078866Z",
     "iopub.status.idle": "2023-04-12T02:14:52.624635Z",
     "shell.execute_reply": "2023-04-12T02:14:52.623932Z",
     "shell.execute_reply.started": "2023-04-12T02:14:52.079361Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义模型训练验证评估函数\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    \"\"\"\n",
    "    Given a dataset, it evals model and computes the metric.\n",
    "\n",
    "    Args:\n",
    "        model(obj:`paddle.nn.Layer`): A model to classify texts.\n",
    "        data_loader(obj:`paddle.io.DataLoader`): The dataset loader which generates batches.\n",
    "        criterion(obj:`paddle.nn.Layer`): It can compute the loss.\n",
    "        metric(obj:`paddle.metric.Metric`): The evaluation metric.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return accu  # 返回准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T02:14:52.626290Z",
     "iopub.status.busy": "2023-04-12T02:14:52.625642Z",
     "iopub.status.idle": "2023-04-12T03:17:56.563852Z",
     "shell.execute_reply": "2023-04-12T03:17:56.563156Z",
     "shell.execute_reply.started": "2023-04-12T02:14:52.626262Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 1.77313, acc: 0.26875\r\n",
      "global step 20, epoch: 1, batch: 20, loss: 1.71304, acc: 0.25781\r\n",
      "global step 30, epoch: 1, batch: 30, loss: 1.70596, acc: 0.25729\r\n",
      "global step 40, epoch: 1, batch: 40, loss: 1.74703, acc: 0.25156\r\n",
      "global step 50, epoch: 1, batch: 50, loss: 1.69862, acc: 0.24250\r\n",
      "global step 60, epoch: 1, batch: 60, loss: 1.75023, acc: 0.24635\r\n",
      "global step 70, epoch: 1, batch: 70, loss: 1.65988, acc: 0.25848\r\n",
      "global step 80, epoch: 1, batch: 80, loss: 1.72270, acc: 0.25664\r\n",
      "global step 90, epoch: 1, batch: 90, loss: 1.61048, acc: 0.25833\r\n",
      "global step 100, epoch: 1, batch: 100, loss: 1.66326, acc: 0.26156\r\n",
      "global step 110, epoch: 1, batch: 110, loss: 1.59231, acc: 0.26080\r\n",
      "global step 120, epoch: 1, batch: 120, loss: 1.61646, acc: 0.25859\r\n",
      "global step 130, epoch: 1, batch: 130, loss: 1.68485, acc: 0.25457\r\n",
      "global step 140, epoch: 1, batch: 140, loss: 1.70649, acc: 0.25536\r\n",
      "global step 150, epoch: 1, batch: 150, loss: 1.75939, acc: 0.25854\r\n",
      "global step 160, epoch: 1, batch: 160, loss: 1.65805, acc: 0.25879\r\n",
      "global step 170, epoch: 1, batch: 170, loss: 1.76455, acc: 0.25882\r\n",
      "global step 180, epoch: 1, batch: 180, loss: 1.74356, acc: 0.25868\r\n",
      "global step 190, epoch: 1, batch: 190, loss: 1.64870, acc: 0.25970\r\n",
      "global step 200, epoch: 1, batch: 200, loss: 1.60744, acc: 0.26062\r\n",
      "global step 210, epoch: 1, batch: 210, loss: 1.65543, acc: 0.26057\r\n",
      "global step 220, epoch: 1, batch: 220, loss: 1.51648, acc: 0.26122\r\n",
      "global step 230, epoch: 1, batch: 230, loss: 1.72085, acc: 0.26005\r\n",
      "global step 240, epoch: 1, batch: 240, loss: 1.54340, acc: 0.26458\r\n",
      "global step 250, epoch: 1, batch: 250, loss: 1.57471, acc: 0.26663\r\n",
      "global step 260, epoch: 1, batch: 260, loss: 1.49007, acc: 0.27296\r\n",
      "global step 270, epoch: 1, batch: 270, loss: 1.65663, acc: 0.27824\r\n",
      "global step 280, epoch: 1, batch: 280, loss: 1.43472, acc: 0.28471\r\n",
      "global step 290, epoch: 1, batch: 290, loss: 1.40596, acc: 0.29095\r\n",
      "global step 300, epoch: 1, batch: 300, loss: 1.38085, acc: 0.29823\r\n",
      "global step 310, epoch: 1, batch: 310, loss: 1.63342, acc: 0.30413\r\n",
      "global step 320, epoch: 1, batch: 320, loss: 1.19659, acc: 0.31260\r\n",
      "global step 330, epoch: 1, batch: 330, loss: 1.20951, acc: 0.32169\r\n",
      "global step 340, epoch: 1, batch: 340, loss: 1.31483, acc: 0.33061\r\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.98692, acc: 0.34125\r\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.97226, acc: 0.35017\r\n",
      "global step 370, epoch: 1, batch: 370, loss: 1.28044, acc: 0.35769\r\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.94414, acc: 0.36637\r\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.97982, acc: 0.37444\r\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.71518, acc: 0.38281\r\n",
      "global step 410, epoch: 1, batch: 410, loss: 0.73263, acc: 0.39070\r\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.90308, acc: 0.39896\r\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.67833, acc: 0.40618\r\n",
      "global step 440, epoch: 1, batch: 440, loss: 1.02738, acc: 0.41335\r\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.82230, acc: 0.42139\r\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.96741, acc: 0.42785\r\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.40098, acc: 0.43438\r\n",
      "global step 480, epoch: 1, batch: 480, loss: 0.71546, acc: 0.44004\r\n",
      "global step 490, epoch: 1, batch: 490, loss: 0.65502, acc: 0.44598\r\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.71675, acc: 0.45206\r\n",
      "global step 510, epoch: 1, batch: 510, loss: 0.79252, acc: 0.45809\r\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.56614, acc: 0.46406\r\n",
      "global step 530, epoch: 1, batch: 530, loss: 0.67014, acc: 0.46934\r\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.70122, acc: 0.47529\r\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.75130, acc: 0.48040\r\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.75178, acc: 0.48477\r\n",
      "global step 570, epoch: 1, batch: 570, loss: 0.78560, acc: 0.48975\r\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.78733, acc: 0.49429\r\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.66904, acc: 0.49921\r\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.51982, acc: 0.50344\r\n",
      "global step 610, epoch: 1, batch: 610, loss: 0.68324, acc: 0.50809\r\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.68849, acc: 0.51225\r\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.64797, acc: 0.51612\r\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.63729, acc: 0.51987\r\n",
      "global step 650, epoch: 1, batch: 650, loss: 0.75845, acc: 0.52370\r\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.65363, acc: 0.52779\r\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.77519, acc: 0.53130\r\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.63359, acc: 0.53516\r\n",
      "global step 690, epoch: 1, batch: 690, loss: 0.87165, acc: 0.53841\r\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.60906, acc: 0.54165\r\n",
      "global step 710, epoch: 1, batch: 710, loss: 0.51291, acc: 0.54511\r\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.40543, acc: 0.54852\r\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.92006, acc: 0.55197\r\n",
      "global step 740, epoch: 1, batch: 740, loss: 0.89611, acc: 0.55410\r\n",
      "global step 750, epoch: 1, batch: 750, loss: 0.85747, acc: 0.55663\r\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.82477, acc: 0.55929\r\n",
      "global step 770, epoch: 1, batch: 770, loss: 0.47732, acc: 0.56213\r\n",
      "global step 780, epoch: 1, batch: 780, loss: 0.55631, acc: 0.56518\r\n",
      "global step 790, epoch: 1, batch: 790, loss: 0.80093, acc: 0.56768\r\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.66129, acc: 0.57035\r\n",
      "global step 810, epoch: 1, batch: 810, loss: 0.40696, acc: 0.57276\r\n",
      "global step 820, epoch: 1, batch: 820, loss: 0.55767, acc: 0.57546\r\n",
      "global step 830, epoch: 1, batch: 830, loss: 0.65081, acc: 0.57812\r\n",
      "global step 840, epoch: 1, batch: 840, loss: 0.89437, acc: 0.58028\r\n",
      "global step 850, epoch: 1, batch: 850, loss: 0.65044, acc: 0.58239\r\n",
      "global step 860, epoch: 1, batch: 860, loss: 0.74705, acc: 0.58434\r\n",
      "global step 870, epoch: 1, batch: 870, loss: 0.91245, acc: 0.58635\r\n",
      "global step 880, epoch: 1, batch: 880, loss: 0.78350, acc: 0.58817\r\n",
      "global step 890, epoch: 1, batch: 890, loss: 0.69032, acc: 0.59010\r\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.76633, acc: 0.59226\r\n",
      "global step 910, epoch: 1, batch: 910, loss: 0.36028, acc: 0.59451\r\n",
      "global step 920, epoch: 1, batch: 920, loss: 0.67175, acc: 0.59637\r\n",
      "global step 930, epoch: 1, batch: 930, loss: 0.65149, acc: 0.59872\r\n",
      "global step 940, epoch: 1, batch: 940, loss: 0.93994, acc: 0.60060\r\n",
      "global step 950, epoch: 1, batch: 950, loss: 0.35474, acc: 0.60234\r\n",
      "global step 960, epoch: 1, batch: 960, loss: 0.67251, acc: 0.60426\r\n",
      "global step 970, epoch: 1, batch: 970, loss: 0.81256, acc: 0.60609\r\n",
      "global step 980, epoch: 1, batch: 980, loss: 0.58891, acc: 0.60820\r\n",
      "global step 990, epoch: 1, batch: 990, loss: 0.61801, acc: 0.60975\r\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.43913, acc: 0.61150\r\n",
      "global step 1010, epoch: 1, batch: 1010, loss: 1.07051, acc: 0.61293\r\n",
      "global step 1020, epoch: 1, batch: 1020, loss: 0.93194, acc: 0.61461\r\n",
      "global step 1030, epoch: 1, batch: 1030, loss: 0.62520, acc: 0.61638\r\n",
      "global step 1040, epoch: 1, batch: 1040, loss: 0.32728, acc: 0.61797\r\n",
      "global step 1050, epoch: 1, batch: 1050, loss: 0.38103, acc: 0.61967\r\n",
      "global step 1060, epoch: 1, batch: 1060, loss: 0.60623, acc: 0.62090\r\n",
      "global step 1070, epoch: 1, batch: 1070, loss: 0.57391, acc: 0.62249\r\n",
      "global step 1080, epoch: 1, batch: 1080, loss: 0.51997, acc: 0.62390\r\n",
      "global step 1090, epoch: 1, batch: 1090, loss: 0.71623, acc: 0.62540\r\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.70202, acc: 0.62673\r\n",
      "global step 1110, epoch: 1, batch: 1110, loss: 0.57913, acc: 0.62798\r\n",
      "global step 1120, epoch: 1, batch: 1120, loss: 0.60845, acc: 0.62913\r\n",
      "global step 1130, epoch: 1, batch: 1130, loss: 0.61333, acc: 0.63050\r\n",
      "eval loss: 0.62025, accu: 0.78500\r\n",
      "0.785\r\n",
      "global step 1140, epoch: 2, batch: 3, loss: 0.47128, acc: 0.85417\r\n",
      "global step 1150, epoch: 2, batch: 13, loss: 0.52452, acc: 0.82933\r\n",
      "global step 1160, epoch: 2, batch: 23, loss: 0.57031, acc: 0.82201\r\n",
      "global step 1170, epoch: 2, batch: 33, loss: 0.49437, acc: 0.82292\r\n",
      "global step 1180, epoch: 2, batch: 43, loss: 0.25115, acc: 0.83576\r\n",
      "global step 1190, epoch: 2, batch: 53, loss: 0.35231, acc: 0.84139\r\n",
      "global step 1200, epoch: 2, batch: 63, loss: 0.49439, acc: 0.83581\r\n",
      "global step 1210, epoch: 2, batch: 73, loss: 0.43025, acc: 0.84075\r\n",
      "global step 1220, epoch: 2, batch: 83, loss: 0.48018, acc: 0.84300\r\n",
      "global step 1230, epoch: 2, batch: 93, loss: 0.53410, acc: 0.84308\r\n",
      "global step 1240, epoch: 2, batch: 103, loss: 1.01424, acc: 0.84314\r\n",
      "global step 1250, epoch: 2, batch: 113, loss: 0.56924, acc: 0.84458\r\n",
      "global step 1260, epoch: 2, batch: 123, loss: 0.41098, acc: 0.84502\r\n",
      "global step 1270, epoch: 2, batch: 133, loss: 0.32987, acc: 0.84398\r\n",
      "global step 1280, epoch: 2, batch: 143, loss: 0.29677, acc: 0.84484\r\n",
      "global step 1290, epoch: 2, batch: 153, loss: 0.29484, acc: 0.84375\r\n",
      "global step 1300, epoch: 2, batch: 163, loss: 0.74151, acc: 0.84452\r\n",
      "global step 1310, epoch: 2, batch: 173, loss: 0.34457, acc: 0.84429\r\n",
      "global step 1320, epoch: 2, batch: 183, loss: 0.60407, acc: 0.84477\r\n",
      "global step 1330, epoch: 2, batch: 193, loss: 0.46860, acc: 0.84488\r\n",
      "global step 1340, epoch: 2, batch: 203, loss: 0.67933, acc: 0.84452\r\n",
      "global step 1350, epoch: 2, batch: 213, loss: 0.48259, acc: 0.84272\r\n",
      "global step 1360, epoch: 2, batch: 223, loss: 0.83539, acc: 0.84123\r\n",
      "global step 1370, epoch: 2, batch: 233, loss: 0.28111, acc: 0.84268\r\n",
      "global step 1380, epoch: 2, batch: 243, loss: 0.41322, acc: 0.84375\r\n",
      "global step 1390, epoch: 2, batch: 253, loss: 0.33029, acc: 0.84573\r\n",
      "global step 1400, epoch: 2, batch: 263, loss: 0.36322, acc: 0.84613\r\n",
      "global step 1410, epoch: 2, batch: 273, loss: 0.56729, acc: 0.84615\r\n",
      "global step 1420, epoch: 2, batch: 283, loss: 0.74970, acc: 0.84530\r\n",
      "global step 1430, epoch: 2, batch: 293, loss: 0.64629, acc: 0.84556\r\n",
      "global step 1440, epoch: 2, batch: 303, loss: 0.47670, acc: 0.84385\r\n",
      "global step 1450, epoch: 2, batch: 313, loss: 0.50161, acc: 0.84375\r\n",
      "global step 1460, epoch: 2, batch: 323, loss: 0.36935, acc: 0.84356\r\n",
      "global step 1470, epoch: 2, batch: 333, loss: 0.44210, acc: 0.84403\r\n",
      "global step 1480, epoch: 2, batch: 343, loss: 0.60921, acc: 0.84375\r\n",
      "global step 1490, epoch: 2, batch: 353, loss: 0.52513, acc: 0.84269\r\n",
      "global step 1500, epoch: 2, batch: 363, loss: 0.35034, acc: 0.84306\r\n",
      "global step 1510, epoch: 2, batch: 373, loss: 0.17532, acc: 0.84266\r\n",
      "global step 1520, epoch: 2, batch: 383, loss: 0.61054, acc: 0.84244\r\n",
      "global step 1530, epoch: 2, batch: 393, loss: 0.42552, acc: 0.84256\r\n",
      "global step 1540, epoch: 2, batch: 403, loss: 0.41209, acc: 0.84142\r\n",
      "global step 1550, epoch: 2, batch: 413, loss: 0.46989, acc: 0.84178\r\n",
      "global step 1560, epoch: 2, batch: 423, loss: 0.57359, acc: 0.84212\r\n",
      "global step 1570, epoch: 2, batch: 433, loss: 0.54969, acc: 0.84173\r\n",
      "global step 1580, epoch: 2, batch: 443, loss: 0.23836, acc: 0.84227\r\n",
      "global step 1590, epoch: 2, batch: 453, loss: 0.73799, acc: 0.84244\r\n",
      "global step 1600, epoch: 2, batch: 463, loss: 0.42548, acc: 0.84274\r\n",
      "global step 1610, epoch: 2, batch: 473, loss: 0.85284, acc: 0.84283\r\n",
      "global step 1620, epoch: 2, batch: 483, loss: 0.57152, acc: 0.84297\r\n",
      "global step 1630, epoch: 2, batch: 493, loss: 0.29097, acc: 0.84229\r\n",
      "global step 1640, epoch: 2, batch: 503, loss: 0.51522, acc: 0.84220\r\n",
      "global step 1650, epoch: 2, batch: 513, loss: 0.46020, acc: 0.84211\r\n",
      "global step 1660, epoch: 2, batch: 523, loss: 0.33764, acc: 0.84202\r\n",
      "global step 1670, epoch: 2, batch: 533, loss: 0.58249, acc: 0.84217\r\n",
      "global step 1680, epoch: 2, batch: 543, loss: 0.38207, acc: 0.84225\r\n",
      "global step 1690, epoch: 2, batch: 553, loss: 0.46500, acc: 0.84268\r\n",
      "global step 1700, epoch: 2, batch: 563, loss: 0.42110, acc: 0.84325\r\n",
      "global step 1710, epoch: 2, batch: 573, loss: 0.42902, acc: 0.84331\r\n",
      "global step 1720, epoch: 2, batch: 583, loss: 0.80281, acc: 0.84321\r\n",
      "global step 1730, epoch: 2, batch: 593, loss: 0.99011, acc: 0.84285\r\n",
      "global step 1740, epoch: 2, batch: 603, loss: 0.35661, acc: 0.84302\r\n",
      "global step 1750, epoch: 2, batch: 613, loss: 0.29107, acc: 0.84293\r\n",
      "global step 1760, epoch: 2, batch: 623, loss: 0.35744, acc: 0.84285\r\n",
      "global step 1770, epoch: 2, batch: 633, loss: 0.39093, acc: 0.84271\r\n",
      "global step 1780, epoch: 2, batch: 643, loss: 0.49287, acc: 0.84249\r\n",
      "global step 1790, epoch: 2, batch: 653, loss: 0.30820, acc: 0.84260\r\n",
      "global step 1800, epoch: 2, batch: 663, loss: 0.43522, acc: 0.84234\r\n",
      "global step 1810, epoch: 2, batch: 673, loss: 0.45833, acc: 0.84268\r\n",
      "global step 1820, epoch: 2, batch: 683, loss: 0.42411, acc: 0.84233\r\n",
      "global step 1830, epoch: 2, batch: 693, loss: 0.46102, acc: 0.84267\r\n",
      "global step 1840, epoch: 2, batch: 703, loss: 0.29091, acc: 0.84322\r\n",
      "global step 1850, epoch: 2, batch: 713, loss: 0.69043, acc: 0.84314\r\n",
      "global step 1860, epoch: 2, batch: 723, loss: 0.61284, acc: 0.84293\r\n",
      "global step 1870, epoch: 2, batch: 733, loss: 0.58544, acc: 0.84273\r\n",
      "global step 1880, epoch: 2, batch: 743, loss: 0.71225, acc: 0.84232\r\n",
      "global step 1890, epoch: 2, batch: 753, loss: 0.29152, acc: 0.84259\r\n",
      "global step 1900, epoch: 2, batch: 763, loss: 0.63910, acc: 0.84252\r\n",
      "global step 1910, epoch: 2, batch: 773, loss: 0.25096, acc: 0.84242\r\n",
      "global step 1920, epoch: 2, batch: 783, loss: 0.80765, acc: 0.84195\r\n",
      "global step 1930, epoch: 2, batch: 793, loss: 0.59362, acc: 0.84170\r\n",
      "global step 1940, epoch: 2, batch: 803, loss: 0.27774, acc: 0.84196\r\n",
      "global step 1950, epoch: 2, batch: 813, loss: 0.21469, acc: 0.84225\r\n",
      "global step 1960, epoch: 2, batch: 823, loss: 0.44314, acc: 0.84235\r\n",
      "global step 1970, epoch: 2, batch: 833, loss: 0.43069, acc: 0.84270\r\n",
      "global step 1980, epoch: 2, batch: 843, loss: 0.76464, acc: 0.84308\r\n",
      "global step 1990, epoch: 2, batch: 853, loss: 0.14342, acc: 0.84324\r\n",
      "global step 2000, epoch: 2, batch: 863, loss: 0.59236, acc: 0.84281\r\n",
      "global step 2010, epoch: 2, batch: 873, loss: 0.79615, acc: 0.84271\r\n",
      "global step 2020, epoch: 2, batch: 883, loss: 0.49977, acc: 0.84276\r\n",
      "global step 2030, epoch: 2, batch: 893, loss: 0.45638, acc: 0.84316\r\n",
      "global step 2040, epoch: 2, batch: 903, loss: 0.39565, acc: 0.84282\r\n",
      "global step 2050, epoch: 2, batch: 913, loss: 0.38898, acc: 0.84303\r\n",
      "global step 2060, epoch: 2, batch: 923, loss: 0.28643, acc: 0.84290\r\n",
      "global step 2070, epoch: 2, batch: 933, loss: 0.41321, acc: 0.84301\r\n",
      "global step 2080, epoch: 2, batch: 943, loss: 0.37733, acc: 0.84325\r\n",
      "global step 2090, epoch: 2, batch: 953, loss: 0.40619, acc: 0.84313\r\n",
      "global step 2100, epoch: 2, batch: 963, loss: 0.75610, acc: 0.84300\r\n",
      "global step 2110, epoch: 2, batch: 973, loss: 0.47664, acc: 0.84298\r\n",
      "global step 2120, epoch: 2, batch: 983, loss: 0.50718, acc: 0.84261\r\n",
      "global step 2130, epoch: 2, batch: 993, loss: 0.48614, acc: 0.84281\r\n",
      "global step 2140, epoch: 2, batch: 1003, loss: 0.34991, acc: 0.84282\r\n",
      "global step 2150, epoch: 2, batch: 1013, loss: 0.48220, acc: 0.84292\r\n",
      "global step 2160, epoch: 2, batch: 1023, loss: 0.27556, acc: 0.84314\r\n",
      "global step 2170, epoch: 2, batch: 1033, loss: 0.43779, acc: 0.84305\r\n",
      "global step 2180, epoch: 2, batch: 1043, loss: 0.21679, acc: 0.84330\r\n",
      "global step 2190, epoch: 2, batch: 1053, loss: 0.35950, acc: 0.84372\r\n",
      "global step 2200, epoch: 2, batch: 1063, loss: 0.13413, acc: 0.84378\r\n",
      "global step 2210, epoch: 2, batch: 1073, loss: 0.45680, acc: 0.84401\r\n",
      "global step 2220, epoch: 2, batch: 1083, loss: 0.56887, acc: 0.84387\r\n",
      "global step 2230, epoch: 2, batch: 1093, loss: 0.32193, acc: 0.84406\r\n",
      "global step 2240, epoch: 2, batch: 1103, loss: 0.68426, acc: 0.84398\r\n",
      "global step 2250, epoch: 2, batch: 1113, loss: 0.45661, acc: 0.84389\r\n",
      "global step 2260, epoch: 2, batch: 1123, loss: 0.53373, acc: 0.84425\r\n",
      "global step 2270, epoch: 2, batch: 1133, loss: 0.50372, acc: 0.84416\r\n",
      "eval loss: 0.60747, accu: 0.78975\r\n",
      "0.78975\r\n",
      "global step 2280, epoch: 3, batch: 6, loss: 0.20331, acc: 0.92188\r\n",
      "global step 2290, epoch: 3, batch: 16, loss: 0.31991, acc: 0.91992\r\n",
      "global step 2300, epoch: 3, batch: 26, loss: 0.43415, acc: 0.92428\r\n",
      "global step 2310, epoch: 3, batch: 36, loss: 0.29632, acc: 0.92535\r\n",
      "global step 2320, epoch: 3, batch: 46, loss: 0.35124, acc: 0.91644\r\n",
      "global step 2330, epoch: 3, batch: 56, loss: 0.45914, acc: 0.91574\r\n",
      "global step 2340, epoch: 3, batch: 66, loss: 0.39971, acc: 0.91572\r\n",
      "global step 2350, epoch: 3, batch: 76, loss: 0.09201, acc: 0.92105\r\n",
      "global step 2360, epoch: 3, batch: 86, loss: 0.12866, acc: 0.92478\r\n",
      "global step 2370, epoch: 3, batch: 96, loss: 0.07985, acc: 0.92578\r\n",
      "global step 2380, epoch: 3, batch: 106, loss: 0.44127, acc: 0.92541\r\n",
      "global step 2390, epoch: 3, batch: 116, loss: 0.12799, acc: 0.92511\r\n",
      "global step 2400, epoch: 3, batch: 126, loss: 0.26897, acc: 0.92386\r\n",
      "global step 2410, epoch: 3, batch: 136, loss: 0.27653, acc: 0.92417\r\n",
      "global step 2420, epoch: 3, batch: 146, loss: 0.25814, acc: 0.92359\r\n",
      "global step 2430, epoch: 3, batch: 156, loss: 0.16902, acc: 0.92368\r\n",
      "global step 2440, epoch: 3, batch: 166, loss: 0.34468, acc: 0.92413\r\n",
      "global step 2450, epoch: 3, batch: 176, loss: 0.18850, acc: 0.92259\r\n",
      "global step 2460, epoch: 3, batch: 186, loss: 0.39991, acc: 0.92171\r\n",
      "global step 2470, epoch: 3, batch: 196, loss: 0.14106, acc: 0.92363\r\n",
      "global step 2480, epoch: 3, batch: 206, loss: 0.33100, acc: 0.92248\r\n",
      "global step 2490, epoch: 3, batch: 216, loss: 0.32341, acc: 0.92318\r\n",
      "global step 2500, epoch: 3, batch: 226, loss: 0.26300, acc: 0.92284\r\n",
      "global step 2510, epoch: 3, batch: 236, loss: 0.27845, acc: 0.92346\r\n",
      "global step 2520, epoch: 3, batch: 246, loss: 0.21577, acc: 0.92391\r\n",
      "global step 2530, epoch: 3, batch: 256, loss: 0.14810, acc: 0.92310\r\n",
      "global step 2540, epoch: 3, batch: 266, loss: 0.19394, acc: 0.92305\r\n",
      "global step 2550, epoch: 3, batch: 276, loss: 0.06342, acc: 0.92335\r\n",
      "global step 2560, epoch: 3, batch: 286, loss: 0.14531, acc: 0.92373\r\n",
      "global step 2570, epoch: 3, batch: 296, loss: 0.31156, acc: 0.92314\r\n",
      "global step 2580, epoch: 3, batch: 306, loss: 0.28633, acc: 0.92269\r\n",
      "global step 2590, epoch: 3, batch: 316, loss: 0.17115, acc: 0.92296\r\n",
      "global step 2600, epoch: 3, batch: 326, loss: 0.11641, acc: 0.92379\r\n",
      "global step 2610, epoch: 3, batch: 336, loss: 0.09834, acc: 0.92411\r\n",
      "global step 2620, epoch: 3, batch: 346, loss: 0.35820, acc: 0.92458\r\n",
      "global step 2630, epoch: 3, batch: 356, loss: 0.09978, acc: 0.92451\r\n",
      "global step 2640, epoch: 3, batch: 366, loss: 0.37955, acc: 0.92392\r\n",
      "global step 2650, epoch: 3, batch: 376, loss: 0.25803, acc: 0.92437\r\n",
      "global step 2660, epoch: 3, batch: 386, loss: 0.12341, acc: 0.92447\r\n",
      "global step 2670, epoch: 3, batch: 396, loss: 0.16246, acc: 0.92479\r\n",
      "global step 2680, epoch: 3, batch: 406, loss: 0.17599, acc: 0.92472\r\n",
      "global step 2690, epoch: 3, batch: 416, loss: 0.10174, acc: 0.92503\r\n",
      "global step 2700, epoch: 3, batch: 426, loss: 0.21168, acc: 0.92466\r\n",
      "global step 2710, epoch: 3, batch: 436, loss: 0.07845, acc: 0.92467\r\n",
      "global step 2720, epoch: 3, batch: 446, loss: 0.28027, acc: 0.92398\r\n",
      "global step 2730, epoch: 3, batch: 456, loss: 0.31900, acc: 0.92393\r\n",
      "global step 2740, epoch: 3, batch: 466, loss: 0.21294, acc: 0.92389\r\n",
      "global step 2750, epoch: 3, batch: 476, loss: 0.10659, acc: 0.92463\r\n",
      "global step 2760, epoch: 3, batch: 486, loss: 0.17081, acc: 0.92509\r\n",
      "global step 2770, epoch: 3, batch: 496, loss: 0.21984, acc: 0.92471\r\n",
      "global step 2780, epoch: 3, batch: 506, loss: 0.22963, acc: 0.92521\r\n",
      "global step 2790, epoch: 3, batch: 516, loss: 0.06360, acc: 0.92508\r\n",
      "global step 2800, epoch: 3, batch: 526, loss: 0.22877, acc: 0.92538\r\n",
      "global step 2810, epoch: 3, batch: 536, loss: 0.12958, acc: 0.92531\r\n",
      "global step 2820, epoch: 3, batch: 546, loss: 0.22485, acc: 0.92525\r\n",
      "global step 2830, epoch: 3, batch: 556, loss: 0.19308, acc: 0.92530\r\n",
      "global step 2840, epoch: 3, batch: 566, loss: 0.40832, acc: 0.92530\r\n",
      "global step 2850, epoch: 3, batch: 576, loss: 0.25456, acc: 0.92529\r\n",
      "global step 2860, epoch: 3, batch: 586, loss: 0.17508, acc: 0.92534\r\n",
      "global step 2870, epoch: 3, batch: 596, loss: 0.31386, acc: 0.92534\r\n",
      "global step 2880, epoch: 3, batch: 606, loss: 0.06231, acc: 0.92548\r\n",
      "global step 2890, epoch: 3, batch: 616, loss: 0.56589, acc: 0.92507\r\n",
      "global step 2900, epoch: 3, batch: 626, loss: 0.16914, acc: 0.92472\r\n",
      "global step 2910, epoch: 3, batch: 636, loss: 0.29320, acc: 0.92472\r\n",
      "global step 2920, epoch: 3, batch: 646, loss: 0.47044, acc: 0.92468\r\n",
      "global step 2930, epoch: 3, batch: 656, loss: 0.22989, acc: 0.92459\r\n",
      "global step 2940, epoch: 3, batch: 666, loss: 0.22497, acc: 0.92469\r\n",
      "global step 2950, epoch: 3, batch: 676, loss: 0.25587, acc: 0.92497\r\n",
      "global step 2960, epoch: 3, batch: 686, loss: 0.43365, acc: 0.92452\r\n",
      "global step 2970, epoch: 3, batch: 696, loss: 0.28813, acc: 0.92466\r\n",
      "global step 2980, epoch: 3, batch: 706, loss: 0.31753, acc: 0.92484\r\n",
      "global step 2990, epoch: 3, batch: 716, loss: 0.19983, acc: 0.92476\r\n",
      "global step 3000, epoch: 3, batch: 726, loss: 0.17908, acc: 0.92497\r\n",
      "global step 3010, epoch: 3, batch: 736, loss: 0.37504, acc: 0.92485\r\n",
      "global step 3020, epoch: 3, batch: 746, loss: 0.56790, acc: 0.92493\r\n",
      "global step 3030, epoch: 3, batch: 756, loss: 0.23828, acc: 0.92431\r\n",
      "global step 3040, epoch: 3, batch: 766, loss: 0.34013, acc: 0.92436\r\n",
      "global step 3050, epoch: 3, batch: 776, loss: 0.52824, acc: 0.92445\r\n",
      "global step 3060, epoch: 3, batch: 786, loss: 0.15391, acc: 0.92450\r\n",
      "global step 3070, epoch: 3, batch: 796, loss: 0.17578, acc: 0.92431\r\n",
      "global step 3080, epoch: 3, batch: 806, loss: 0.03376, acc: 0.92432\r\n",
      "global step 3090, epoch: 3, batch: 816, loss: 0.19461, acc: 0.92456\r\n",
      "global step 3100, epoch: 3, batch: 826, loss: 0.09560, acc: 0.92445\r\n",
      "global step 3110, epoch: 3, batch: 836, loss: 0.24798, acc: 0.92445\r\n",
      "global step 3120, epoch: 3, batch: 846, loss: 0.21201, acc: 0.92472\r\n",
      "global step 3130, epoch: 3, batch: 856, loss: 0.21269, acc: 0.92458\r\n",
      "global step 3140, epoch: 3, batch: 866, loss: 0.37178, acc: 0.92436\r\n",
      "global step 3150, epoch: 3, batch: 876, loss: 0.19284, acc: 0.92434\r\n",
      "global step 3160, epoch: 3, batch: 886, loss: 0.14608, acc: 0.92427\r\n",
      "global step 3170, epoch: 3, batch: 896, loss: 0.14564, acc: 0.92421\r\n",
      "global step 3180, epoch: 3, batch: 906, loss: 0.33724, acc: 0.92422\r\n",
      "global step 3190, epoch: 3, batch: 916, loss: 0.11124, acc: 0.92450\r\n",
      "global step 3200, epoch: 3, batch: 926, loss: 0.35018, acc: 0.92451\r\n",
      "global step 3210, epoch: 3, batch: 936, loss: 0.19109, acc: 0.92441\r\n",
      "global step 3220, epoch: 3, batch: 946, loss: 0.18580, acc: 0.92429\r\n",
      "global step 3230, epoch: 3, batch: 956, loss: 0.27107, acc: 0.92413\r\n",
      "global step 3240, epoch: 3, batch: 966, loss: 0.37620, acc: 0.92440\r\n",
      "global step 3250, epoch: 3, batch: 976, loss: 0.30954, acc: 0.92431\r\n",
      "global step 3260, epoch: 3, batch: 986, loss: 0.10781, acc: 0.92419\r\n",
      "global step 3270, epoch: 3, batch: 996, loss: 0.16528, acc: 0.92423\r\n",
      "global step 3280, epoch: 3, batch: 1006, loss: 0.16448, acc: 0.92393\r\n",
      "global step 3290, epoch: 3, batch: 1016, loss: 0.17871, acc: 0.92381\r\n",
      "global step 3300, epoch: 3, batch: 1026, loss: 0.34634, acc: 0.92379\r\n",
      "global step 3310, epoch: 3, batch: 1036, loss: 0.29801, acc: 0.92399\r\n",
      "global step 3320, epoch: 3, batch: 1046, loss: 0.13671, acc: 0.92418\r\n",
      "global step 3330, epoch: 3, batch: 1056, loss: 0.26390, acc: 0.92424\r\n",
      "global step 3340, epoch: 3, batch: 1066, loss: 0.12963, acc: 0.92422\r\n",
      "global step 3350, epoch: 3, batch: 1076, loss: 0.37816, acc: 0.92426\r\n",
      "global step 3360, epoch: 3, batch: 1086, loss: 0.23890, acc: 0.92438\r\n",
      "global step 3370, epoch: 3, batch: 1096, loss: 0.22869, acc: 0.92418\r\n",
      "global step 3380, epoch: 3, batch: 1106, loss: 0.37744, acc: 0.92425\r\n",
      "global step 3390, epoch: 3, batch: 1116, loss: 0.27478, acc: 0.92434\r\n",
      "global step 3400, epoch: 3, batch: 1126, loss: 0.29164, acc: 0.92432\r\n",
      "global step 3410, epoch: 3, batch: 1136, loss: 0.10364, acc: 0.92421\r\n",
      "eval loss: 0.69299, accu: 0.78650\r\n",
      "0.7865\r\n",
      "global step 3420, epoch: 4, batch: 9, loss: 0.34629, acc: 0.97569\r\n",
      "global step 3430, epoch: 4, batch: 19, loss: 0.09838, acc: 0.96875\r\n",
      "global step 3440, epoch: 4, batch: 29, loss: 0.09996, acc: 0.96552\r\n",
      "global step 3450, epoch: 4, batch: 39, loss: 0.12534, acc: 0.96394\r\n",
      "global step 3460, epoch: 4, batch: 49, loss: 0.10845, acc: 0.96684\r\n",
      "global step 3470, epoch: 4, batch: 59, loss: 0.28009, acc: 0.96504\r\n",
      "global step 3480, epoch: 4, batch: 69, loss: 0.29762, acc: 0.96377\r\n",
      "global step 3490, epoch: 4, batch: 79, loss: 0.06939, acc: 0.96440\r\n",
      "global step 3500, epoch: 4, batch: 89, loss: 0.07758, acc: 0.96489\r\n",
      "global step 3510, epoch: 4, batch: 99, loss: 0.17758, acc: 0.96528\r\n",
      "global step 3520, epoch: 4, batch: 109, loss: 0.09196, acc: 0.96646\r\n",
      "global step 3530, epoch: 4, batch: 119, loss: 0.32380, acc: 0.96507\r\n",
      "global step 3540, epoch: 4, batch: 129, loss: 0.15084, acc: 0.96560\r\n",
      "global step 3550, epoch: 4, batch: 139, loss: 0.05759, acc: 0.96628\r\n",
      "global step 3560, epoch: 4, batch: 149, loss: 0.15424, acc: 0.96686\r\n",
      "global step 3570, epoch: 4, batch: 159, loss: 0.07447, acc: 0.96757\r\n",
      "global step 3580, epoch: 4, batch: 169, loss: 0.13968, acc: 0.96764\r\n",
      "global step 3590, epoch: 4, batch: 179, loss: 0.07049, acc: 0.96770\r\n",
      "global step 3600, epoch: 4, batch: 189, loss: 0.05907, acc: 0.96660\r\n",
      "global step 3610, epoch: 4, batch: 199, loss: 0.14357, acc: 0.96655\r\n",
      "global step 3620, epoch: 4, batch: 209, loss: 0.03470, acc: 0.96696\r\n",
      "global step 3630, epoch: 4, batch: 219, loss: 0.11616, acc: 0.96575\r\n",
      "global step 3640, epoch: 4, batch: 229, loss: 0.38443, acc: 0.96520\r\n",
      "global step 3650, epoch: 4, batch: 239, loss: 0.03483, acc: 0.96587\r\n",
      "global step 3660, epoch: 4, batch: 249, loss: 0.02877, acc: 0.96574\r\n",
      "global step 3670, epoch: 4, batch: 259, loss: 0.22823, acc: 0.96597\r\n",
      "global step 3680, epoch: 4, batch: 269, loss: 0.27971, acc: 0.96538\r\n",
      "global step 3690, epoch: 4, batch: 279, loss: 0.04199, acc: 0.96505\r\n",
      "global step 3700, epoch: 4, batch: 289, loss: 0.20323, acc: 0.96507\r\n",
      "global step 3710, epoch: 4, batch: 299, loss: 0.04822, acc: 0.96530\r\n",
      "global step 3720, epoch: 4, batch: 309, loss: 0.04559, acc: 0.96541\r\n",
      "global step 3730, epoch: 4, batch: 319, loss: 0.17872, acc: 0.96503\r\n",
      "global step 3740, epoch: 4, batch: 329, loss: 0.15855, acc: 0.96467\r\n",
      "global step 3750, epoch: 4, batch: 339, loss: 0.25512, acc: 0.96497\r\n",
      "global step 3760, epoch: 4, batch: 349, loss: 0.20237, acc: 0.96463\r\n",
      "global step 3770, epoch: 4, batch: 359, loss: 0.09401, acc: 0.96483\r\n",
      "global step 3780, epoch: 4, batch: 369, loss: 0.07688, acc: 0.96426\r\n",
      "global step 3790, epoch: 4, batch: 379, loss: 0.06211, acc: 0.96479\r\n",
      "global step 3800, epoch: 4, batch: 389, loss: 0.18692, acc: 0.96481\r\n",
      "global step 3810, epoch: 4, batch: 399, loss: 0.09402, acc: 0.96468\r\n",
      "global step 3820, epoch: 4, batch: 409, loss: 0.15460, acc: 0.96462\r\n",
      "global step 3830, epoch: 4, batch: 419, loss: 0.10238, acc: 0.96465\r\n",
      "global step 3840, epoch: 4, batch: 429, loss: 0.10686, acc: 0.96445\r\n",
      "global step 3850, epoch: 4, batch: 439, loss: 0.14873, acc: 0.96448\r\n",
      "global step 3860, epoch: 4, batch: 449, loss: 0.13930, acc: 0.96437\r\n",
      "global step 3870, epoch: 4, batch: 459, loss: 0.26179, acc: 0.96405\r\n",
      "global step 3880, epoch: 4, batch: 469, loss: 0.18679, acc: 0.96402\r\n",
      "global step 3890, epoch: 4, batch: 479, loss: 0.14816, acc: 0.96379\r\n",
      "global step 3900, epoch: 4, batch: 489, loss: 0.02031, acc: 0.96396\r\n",
      "global step 3910, epoch: 4, batch: 499, loss: 0.30875, acc: 0.96387\r\n",
      "global step 3920, epoch: 4, batch: 509, loss: 0.04505, acc: 0.96415\r\n",
      "global step 3930, epoch: 4, batch: 519, loss: 0.06032, acc: 0.96447\r\n",
      "global step 3940, epoch: 4, batch: 529, loss: 0.04880, acc: 0.96450\r\n",
      "global step 3950, epoch: 4, batch: 539, loss: 0.26168, acc: 0.96452\r\n",
      "global step 3960, epoch: 4, batch: 549, loss: 0.03518, acc: 0.96454\r\n",
      "global step 3970, epoch: 4, batch: 559, loss: 0.08448, acc: 0.96422\r\n",
      "global step 3980, epoch: 4, batch: 569, loss: 0.06696, acc: 0.96447\r\n",
      "global step 3990, epoch: 4, batch: 579, loss: 0.03824, acc: 0.96476\r\n",
      "global step 4000, epoch: 4, batch: 589, loss: 0.07938, acc: 0.96488\r\n",
      "global step 4010, epoch: 4, batch: 599, loss: 0.08232, acc: 0.96494\r\n",
      "global step 4020, epoch: 4, batch: 609, loss: 0.07646, acc: 0.96495\r\n",
      "global step 4030, epoch: 4, batch: 619, loss: 0.07180, acc: 0.96501\r\n",
      "global step 4040, epoch: 4, batch: 629, loss: 0.09511, acc: 0.96483\r\n",
      "global step 4050, epoch: 4, batch: 639, loss: 0.07618, acc: 0.96484\r\n",
      "global step 4060, epoch: 4, batch: 649, loss: 0.03110, acc: 0.96475\r\n",
      "global step 4070, epoch: 4, batch: 659, loss: 0.04713, acc: 0.96467\r\n",
      "global step 4080, epoch: 4, batch: 669, loss: 0.30664, acc: 0.96445\r\n",
      "global step 4090, epoch: 4, batch: 679, loss: 0.19743, acc: 0.96465\r\n",
      "global step 4100, epoch: 4, batch: 689, loss: 0.24527, acc: 0.96444\r\n",
      "global step 4110, epoch: 4, batch: 699, loss: 0.05933, acc: 0.96428\r\n",
      "global step 4120, epoch: 4, batch: 709, loss: 0.12393, acc: 0.96408\r\n",
      "global step 4130, epoch: 4, batch: 719, loss: 0.04186, acc: 0.96410\r\n",
      "global step 4140, epoch: 4, batch: 729, loss: 0.32691, acc: 0.96416\r\n",
      "global step 4150, epoch: 4, batch: 739, loss: 0.02096, acc: 0.96418\r\n",
      "global step 4160, epoch: 4, batch: 749, loss: 0.35885, acc: 0.96395\r\n",
      "global step 4170, epoch: 4, batch: 759, loss: 0.06123, acc: 0.96397\r\n",
      "global step 4180, epoch: 4, batch: 769, loss: 0.13846, acc: 0.96395\r\n",
      "global step 4190, epoch: 4, batch: 779, loss: 0.02228, acc: 0.96422\r\n",
      "global step 4200, epoch: 4, batch: 789, loss: 0.05817, acc: 0.96416\r\n",
      "global step 4210, epoch: 4, batch: 799, loss: 0.05897, acc: 0.96441\r\n",
      "global step 4220, epoch: 4, batch: 809, loss: 0.09533, acc: 0.96446\r\n",
      "global step 4230, epoch: 4, batch: 819, loss: 0.04837, acc: 0.96444\r\n",
      "global step 4240, epoch: 4, batch: 829, loss: 0.05922, acc: 0.96457\r\n",
      "global step 4250, epoch: 4, batch: 839, loss: 0.14347, acc: 0.96469\r\n",
      "global step 4260, epoch: 4, batch: 849, loss: 0.19284, acc: 0.96455\r\n",
      "global step 4270, epoch: 4, batch: 859, loss: 0.10882, acc: 0.96460\r\n",
      "global step 4280, epoch: 4, batch: 869, loss: 0.17263, acc: 0.96440\r\n",
      "global step 4290, epoch: 4, batch: 879, loss: 0.25084, acc: 0.96448\r\n",
      "global step 4300, epoch: 4, batch: 889, loss: 0.05792, acc: 0.96471\r\n",
      "global step 4310, epoch: 4, batch: 899, loss: 0.02484, acc: 0.96496\r\n",
      "global step 4320, epoch: 4, batch: 909, loss: 0.04463, acc: 0.96500\r\n",
      "global step 4330, epoch: 4, batch: 919, loss: 0.15736, acc: 0.96474\r\n",
      "global step 4340, epoch: 4, batch: 929, loss: 0.03321, acc: 0.96488\r\n",
      "global step 4350, epoch: 4, batch: 939, loss: 0.22287, acc: 0.96502\r\n",
      "global step 4360, epoch: 4, batch: 949, loss: 0.05238, acc: 0.96513\r\n",
      "global step 4370, epoch: 4, batch: 959, loss: 0.23380, acc: 0.96517\r\n",
      "global step 4380, epoch: 4, batch: 969, loss: 0.05623, acc: 0.96511\r\n",
      "global step 4390, epoch: 4, batch: 979, loss: 0.10830, acc: 0.96517\r\n",
      "global step 4400, epoch: 4, batch: 989, loss: 0.04244, acc: 0.96512\r\n",
      "global step 4410, epoch: 4, batch: 999, loss: 0.27088, acc: 0.96531\r\n",
      "global step 4420, epoch: 4, batch: 1009, loss: 0.27660, acc: 0.96525\r\n",
      "global step 4430, epoch: 4, batch: 1019, loss: 0.08895, acc: 0.96538\r\n",
      "global step 4440, epoch: 4, batch: 1029, loss: 0.06685, acc: 0.96529\r\n",
      "global step 4450, epoch: 4, batch: 1039, loss: 0.18173, acc: 0.96529\r\n",
      "global step 4460, epoch: 4, batch: 1049, loss: 0.29415, acc: 0.96544\r\n",
      "global step 4470, epoch: 4, batch: 1059, loss: 0.11610, acc: 0.96547\r\n",
      "global step 4480, epoch: 4, batch: 1069, loss: 0.09377, acc: 0.96551\r\n",
      "global step 4490, epoch: 4, batch: 1079, loss: 0.04420, acc: 0.96545\r\n",
      "global step 4500, epoch: 4, batch: 1089, loss: 0.02127, acc: 0.96542\r\n",
      "global step 4510, epoch: 4, batch: 1099, loss: 0.04614, acc: 0.96571\r\n",
      "global step 4520, epoch: 4, batch: 1109, loss: 0.18681, acc: 0.96571\r\n",
      "global step 4530, epoch: 4, batch: 1119, loss: 0.03126, acc: 0.96576\r\n",
      "global step 4540, epoch: 4, batch: 1129, loss: 0.20658, acc: 0.96576\r\n",
      "eval loss: 0.78209, accu: 0.78450\r\n",
      "0.7845\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-12 11:17:56,554] [    INFO] - tokenizer config file saved in checkpoint/tokenizer_config.json\r\n",
      "[2023-04-12 11:17:56,557] [    INFO] - Special tokens file saved in checkpoint/special_tokens_map.json\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('checkpoint/tokenizer_config.json',\n",
       " 'checkpoint/special_tokens_map.json',\n",
       " 'checkpoint/added_tokens.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练：\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "save_dir = \"checkpoint\"\n",
    "if not  os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "pre_accu=0\n",
    "accu=0\n",
    "global_step = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, segment_ids, labels = batch\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0 :\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "    # 每轮结束对验证集进行评估\n",
    "    accu = evaluate(model, criterion, metric, dev_data_loader)\n",
    "    print(accu)\n",
    "    if accu > pre_accu:\n",
    "        # 保存较上一轮效果更优的模型参数\n",
    "        save_param_path = os.path.join(save_dir, 'model_state.pdparams')  # 保存模型参数\n",
    "        paddle.save(model.state_dict(), save_param_path)\n",
    "        pre_accu=accu\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:17:56.565712Z",
     "iopub.status.busy": "2023-04-12T03:17:56.565114Z",
     "iopub.status.idle": "2023-04-12T03:17:58.641243Z",
     "shell.execute_reply": "2023-04-12T03:17:58.640578Z",
     "shell.execute_reply.started": "2023-04-12T03:17:56.565683Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parameters from checkpoint/model_state.pdparams\r\n"
     ]
    }
   ],
   "source": [
    "# 加载在验证集上效果最优的一轮的模型参数\n",
    "import os\n",
    "import paddle\n",
    "\n",
    "params_path = 'checkpoint/model_state.pdparams'\n",
    "if params_path and os.path.isfile(params_path):\n",
    "    # 加载模型参数\n",
    "    state_dict = paddle.load(params_path)\n",
    "    model.set_dict(state_dict)\n",
    "    print(\"Loaded parameters from %s\" % params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T03:17:58.642826Z",
     "iopub.status.busy": "2023-04-12T03:17:58.642225Z",
     "iopub.status.idle": "2023-04-12T03:17:58.645557Z",
     "shell.execute_reply": "2023-04-12T03:17:58.644970Z",
     "shell.execute_reply.started": "2023-04-12T03:17:58.642799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 由于data目录下文件不保存，故将训练好的模型参数复制到work目录下便于存储\n",
    "# !cp /home/aistudio/data/data104703/checkpoint/model_state.pdparams /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:17:58.646912Z",
     "iopub.status.busy": "2023-04-12T03:17:58.646399Z",
     "iopub.status.idle": "2023-04-12T03:18:31.410682Z",
     "shell.execute_reply": "2023-04-12T03:18:31.409801Z",
     "shell.execute_reply.started": "2023-04-12T03:17:58.646890Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.60747, accu: 0.78975\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78975"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试最优模型参数在验证集上的分数\n",
    "evaluate(model, criterion, metric, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:18:31.412497Z",
     "iopub.status.busy": "2023-04-12T03:18:31.412005Z",
     "iopub.status.idle": "2023-04-12T03:19:36.327849Z",
     "shell.execute_reply": "2023-04-12T03:19:36.327036Z",
     "shell.execute_reply.started": "2023-04-12T03:18:31.412467Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.60134, accu: 0.79025\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79025"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对测试集进行评估\n",
    "evaluate(model, criterion, metric, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:19:36.329700Z",
     "iopub.status.busy": "2023-04-12T03:19:36.329096Z",
     "iopub.status.idle": "2023-04-12T03:19:36.338189Z",
     "shell.execute_reply": "2023-04-12T03:19:36.337573Z",
     "shell.execute_reply.started": "2023-04-12T03:19:36.329671Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义模型预测函数\n",
    "def predict(model, data, tokenizer, label_map, batch_size=1):\n",
    "    examples = []\n",
    "    for text in data:\n",
    "        input_ids, segment_ids = convert_example(\n",
    "            text,\n",
    "            tokenizer,\n",
    "            max_seq_length=128,\n",
    "            is_test=True)\n",
    "        examples.append((input_ids, segment_ids))\n",
    "\n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
    "    ): fn(samples)\n",
    "\n",
    "    # Seperates data into some batches.\n",
    "    batches = []\n",
    "    one_batch = []\n",
    "    for example in examples:\n",
    "        one_batch.append(example)\n",
    "        if len(one_batch) == batch_size:\n",
    "            batches.append(one_batch)\n",
    "            one_batch = []\n",
    "    if one_batch:\n",
    "        # The last batch whose size is less than the config batch_size setting.\n",
    "        batches.append(one_batch)\n",
    "\n",
    "    results = []\n",
    "    model.eval()\n",
    "    for batch in batches:\n",
    "        input_ids, segment_ids = batchify_fn(batch)\n",
    "        input_ids = paddle.to_tensor(input_ids)\n",
    "        segment_ids = paddle.to_tensor(segment_ids)\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        idx = paddle.argmax(probs, axis=1).numpy()\n",
    "        idx = idx.tolist()\n",
    "        labels = [label_map[i] for i in idx]\n",
    "        results.extend(labels)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:19:36.339498Z",
     "iopub.status.busy": "2023-04-12T03:19:36.339025Z",
     "iopub.status.idle": "2023-04-12T03:19:36.347705Z",
     "shell.execute_reply": "2023-04-12T03:19:36.347131Z",
     "shell.execute_reply.started": "2023-04-12T03:19:36.339475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'happy', 1: 'sad', 2: 'neutral', 3: 'fear', 4: 'angry', 5: 'surprise'}\r\n"
     ]
    }
   ],
   "source": [
    "# 定义要进行分类的类别\n",
    "label_list=list(train.label.unique())\n",
    "label_map = { \n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:19:36.348996Z",
     "iopub.status.busy": "2023-04-12T03:19:36.348525Z",
     "iopub.status.idle": "2023-04-12T03:19:36.622747Z",
     "shell.execute_reply": "2023-04-12T03:19:36.622080Z",
     "shell.execute_reply.started": "2023-04-12T03:19:36.348974Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 更年期的女boss真的让人受不了，烦躁 \t Lable: angry\r\n",
      "Data: 尼玛吓死我了，人家剪个头发回来跟劳改犯一样短的可怕，后面什么鬼[黑线][黑线][黑线][白眼][白眼] \t Lable: fear\r\n",
      "Data: 一个人真无聊，美食都没味了，你要在就好了…唉……… \t Lable: sad\r\n",
      "Data: 这个村的年轻人大多数都出外打工。 \t Lable: neutral\r\n",
      "Data: 谢谢honey们帮我庆祝生日！！！谢谢你们的祝福，谢谢身边的所有人！爱你们 \t Lable: happy\r\n",
      "Data: 我竟然才知道我有一个富二代加官二代加红二代的朋友 \t Lable: surprise\r\n"
     ]
    }
   ],
   "source": [
    "# 定义要进行预测的样本数据\n",
    "data = [\n",
    "    # angry\n",
    "    {\"text_a\": '更年期的女boss真的让人受不了，烦躁'},\n",
    "    # fear\n",
    "    {\"text_a\":'尼玛吓死我了，人家剪个头发回来跟劳改犯一样短的可怕，后面什么鬼[黑线][黑线][黑线][白眼][白眼]'},\n",
    "    # sad\n",
    "    {\"text_a\":'一个人真无聊，美食都没味了，你要在就好了…唉………'},\n",
    "    # neutral\n",
    "    {\"text_a\":\"这个村的年轻人大多数都出外打工。\"},\n",
    "    # happy\n",
    "    {\"text_a\":\"谢谢honey们帮我庆祝生日！！！谢谢你们的祝福，谢谢身边的所有人！爱你们\"},\n",
    "    # surprise\n",
    "    {\"text_a\":\"我竟然才知道我有一个富二代加官二代加红二代的朋友\"}\n",
    "]\n",
    "\n",
    "results = predict(model, data, tokenizer, label_map, batch_size=1)\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text['text_a'], results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 读取文件进行批量预测并生成结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:19:36.624313Z",
     "iopub.status.busy": "2023-04-12T03:19:36.623692Z",
     "iopub.status.idle": "2023-04-12T03:19:36.652646Z",
     "shell.execute_reply": "2023-04-12T03:19:36.652044Z",
     "shell.execute_reply.started": "2023-04-12T03:19:36.624287Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>//@UNIQ-王一博:#致敬疫情前线医护人员#你们辛苦了！愿平安！[心]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>幸亏我爸妈听话//@北国佳人李春姬:令人窒息</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我大河南！！！！[good][good][good][good][good][good]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#疫情地图#鸡蛋挺住#青海祈福# ? ??</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>肏//@马睿_Ray:[doge]//@Erlang:[doge]//@沈沉舟:那是2003...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a    label\n",
       "0              //@UNIQ-王一博:#致敬疫情前线医护人员#你们辛苦了！愿平安！[心]    happy\n",
       "1                             幸亏我爸妈听话//@北国佳人李春姬:令人窒息     fear\n",
       "2       我大河南！！！！[good][good][good][good][good][good]    happy\n",
       "3                              #疫情地图#鸡蛋挺住#青海祈福# ? ??    happy\n",
       "4  肏//@马睿_Ray:[doge]//@Erlang:[doge]//@沈沉舟:那是2003...  neutral"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 扩展：读取测试集文件并进行预测，一般用于比赛结果提交或对文件进行批量预测场景\n",
    "test = pd.read_csv('./test.csv',sep='\\t')  # 读取测试集\n",
    "# 读取数据前5条\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:19:36.653906Z",
     "iopub.status.busy": "2023-04-12T03:19:36.653576Z",
     "iopub.status.idle": "2023-04-12T03:19:36.661070Z",
     "shell.execute_reply": "2023-04-12T03:19:36.660461Z",
     "shell.execute_reply.started": "2023-04-12T03:19:36.653883Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义对数据的预处理函数,处理为指定格式\n",
    "def preprocess_prediction_data(data):\n",
    "    examples = []\n",
    "    for text_a in data:\n",
    "        examples.append({\"text_a\": text_a})\n",
    "    return examples\n",
    "\n",
    "# 对测试集数据进行格式处理\n",
    "data1 = list(test.text_a)\n",
    "examples = preprocess_prediction_data(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:19:36.662324Z",
     "iopub.status.busy": "2023-04-12T03:19:36.661899Z",
     "iopub.status.idle": "2023-04-12T03:22:25.582549Z",
     "shell.execute_reply": "2023-04-12T03:22:25.581363Z",
     "shell.execute_reply.started": "2023-04-12T03:19:36.662301Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = predict(model, examples, tokenizer, label_map, batch_size=2)   # 对测试集进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:22:25.584921Z",
     "iopub.status.busy": "2023-04-12T03:22:25.584440Z",
     "iopub.status.idle": "2023-04-12T03:22:25.590190Z",
     "shell.execute_reply": "2023-04-12T03:22:25.589529Z",
     "shell.execute_reply.started": "2023-04-12T03:22:25.584890Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 保存对测试集的预测结果文件，此处设置保存格式为text_a,label\n",
    "results = pd.DataFrame(results)\n",
    "results.columns = [\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:22:25.591247Z",
     "iopub.status.busy": "2023-04-12T03:22:25.591030Z",
     "iopub.status.idle": "2023-04-12T03:22:25.601750Z",
     "shell.execute_reply": "2023-04-12T03:22:25.601161Z",
     "shell.execute_reply.started": "2023-04-12T03:22:25.591227Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)\r\n"
     ]
    }
   ],
   "source": [
    "results['text_a'] = test['text_a']\n",
    "results = results[['text_a','label']]\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:22:25.602982Z",
     "iopub.status.busy": "2023-04-12T03:22:25.602775Z",
     "iopub.status.idle": "2023-04-12T03:22:25.628247Z",
     "shell.execute_reply": "2023-04-12T03:22:25.627656Z",
     "shell.execute_reply.started": "2023-04-12T03:22:25.602963Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 保存结果文件\n",
    "results.to_csv('./submission.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:22:25.633223Z",
     "iopub.status.busy": "2023-04-12T03:22:25.632660Z",
     "iopub.status.idle": "2023-04-12T03:22:25.640324Z",
     "shell.execute_reply": "2023-04-12T03:22:25.639764Z",
     "shell.execute_reply.started": "2023-04-12T03:22:25.633199Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>//@UNIQ-王一博:#致敬疫情前线医护人员#你们辛苦了！愿平安！[心]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>幸亏我爸妈听话//@北国佳人李春姬:令人窒息</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我大河南！！！！[good][good][good][good][good][good]</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#疫情地图#鸡蛋挺住#青海祈福# ? ??</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>肏//@马睿_Ray:[doge]//@Erlang:[doge]//@沈沉舟:那是2003...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a    label\n",
       "0              //@UNIQ-王一博:#致敬疫情前线医护人员#你们辛苦了！愿平安！[心]    happy\n",
       "1                             幸亏我爸妈听话//@北国佳人李春姬:令人窒息     fear\n",
       "2       我大河南！！！！[good][good][good][good][good][good]    happy\n",
       "3                              #疫情地图#鸡蛋挺住#青海祈福# ? ??    happy\n",
       "4  肏//@马睿_Ray:[doge]//@Erlang:[doge]//@沈沉舟:那是2003...  neutral"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看预测结果前5条\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-Score评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-12T03:22:25.641590Z",
     "iopub.status.busy": "2023-04-12T03:22:25.641371Z",
     "iopub.status.idle": "2023-04-12T03:22:25.728042Z",
     "shell.execute_reply": "2023-04-12T03:22:25.727443Z",
     "shell.execute_reply.started": "2023-04-12T03:22:25.641562Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7397494396513095 0.7335228407245303 0.7520111527052853\r\n"
     ]
    }
   ],
   "source": [
    "# 由于此次使用的测试集是已经提供了真实标签的，因此我们还可以通过其真实标签和预测的标签进行F1-Score评估，F1-Score评估也是目前比赛中常用的一个评估指标\n",
    "\n",
    "# 转换预测结果标签格式为list\n",
    "y_pre = np.array(results['label'])\n",
    "y_pre =y_pre.tolist()\n",
    "\n",
    "# 转换测试集的真实类别标签格式为list\n",
    "y_val = np.array(test['label'])\n",
    "y_val =y_val.tolist()\n",
    "\n",
    "# 计算预测结果的F1-score值\n",
    "from sklearn.metrics import precision_recall_fscore_support,f1_score,precision_score,recall_score\n",
    "f1 = f1_score(y_val, y_pre, average='macro')  # F1-score\n",
    "p = precision_score(y_val, y_pre, average='macro')  # 精准度 / 查准率\n",
    "r = recall_score(y_val, y_pre, average='macro')  # 召回率 / 查全率\n",
    "print(f1, p, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ps:感兴趣的可以在基线模型的基础上通过调参优化、选用其他预训练模型、数据增强和清洗、多模型结果融合、修改网络结构等方式进一步优化提升效果！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四.项目总结\n",
    "\n",
    "1.本项目主要使用了SMP2020微博情绪分类数据集，该数据集可以很好地适用于构建细粒度的微情感分析模型或也可以作为其他微情感分析数据集的一个很好补充。感兴趣的可以使用该数据集进行更多的扩展。\n",
    "\n",
    "该数据集相关比赛[SMP2020微博情绪分类技术评测](http://39.97.118.137/)已经结束，感兴趣的可以前往其官网页下载并学习Top选手们的技术报告&汇报PPT分享等。在GitHub搜索SMP2020即可查看top选手们的开源代码。\n",
    "\n",
    "2.本项目还提供了基于PaddleNLP的预训练模型微调通用代码，使用上参照第二部分将训练和验证集数据处理为text_a,label格式后即可直接套用于类似比赛或项目中去。如想要使用其他预训练模型简单修改模型加载处的代码即可。\n",
    "\n",
    "3.关于微情感分析系统项目实战，感兴趣的可以参考我之前的项目：[PaddleHub实战：基于OCEMOTION的中文微情感分析系统](https://aistudio.baidu.com/aistudio/projectdetail/2211726)\n",
    "\n",
    "4.关于PaddleNLP的使用，建议多阅读官方文档[PaddleNLP文档](https://paddlenlp.readthedocs.io/zh/latest/get_started/quick_start.html)\n",
    "\n",
    "PaddleNLP的github地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)  有问题难以解决的话可以在github上提issue。\n",
    "\n",
    "若大家喜欢，希望能够fork、喜欢、关注三连！❤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五.作者介绍\n",
    "\n",
    "> 昵称：[炼丹师233](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406)\n",
    "\n",
    "> [飞桨开发者技术专家 PPDE](https://www.paddlepaddle.org.cn/ppde)\n",
    "\n",
    "\n",
    "> Github地址：[https://github.com/hchhtc123](https://github.com/hchhtc123)\n",
    "\n",
    "> 研究方向： 全栈小菜鸡，主攻大数据开发和NLP方向，喜欢捣鼓有趣项目。\n",
    "\n",
    "> [https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406) 关注我，下次带来更多精彩项目分享！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
